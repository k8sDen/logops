# Сбор и обработка логов Nginx с использованием Rsyslog, Kafka, Vector и ELK

## Описание проекта

Данный проект предназначен для автоматизации сбора, парсинга и анализа логов Nginx с использованием Rsyslog, Kafka и Vector с последующим сохранением в кластер Elasticsearch для анализа через Kibana.  
**Схема архитектуры:** Nginx + Rsyslog → Kafka → Vector → ELK (Elasticsearch + Kibana).

---

## Схема работы

1. **Nginx** генерирует access-логи.
2. Логи передаются с помощью **Rsyslog** в **Kafka**.
3. **Kafka** накапливает сообщения и передает их в **Vector**.
4. **Vector** парсит логи с помощью **grok patterns** и отправляет их в **Elasticsearch**.
5. **Kibana** предоставляет интерфейс для визуализации логов.


## Папки
development -  одиночные узлы.
production - включена кластеризация.
---
## Запуск проекта
1. sudo chmod +x elasticsearch/setup-elasticsearch.sh
2. cd development
3. docker compose up -d --force-recreate

---
kibana: elastic test123
---

## Ответы на вопросы
1. Опишите логику работы Kafka, offset, partition, group_id
Kafka - cистема обработки потоковых данных в реальном времени. Producer - отправляет сообщения в топик. Consumer - читает сообщения из топика.Topic - канал для обмена сообщениями. В нашем случае **nginx-logs-topic**. Partition - логическое деление топика для параллельной обработки. Offset - уникальный номер сообщения в партиции, отслеживающий его позицию.
Group ID - группа потребителей, позволяющая распределять партиции между ними для параллельной обработки.

2.Опишите логику работы ILM, index-patterns, data_view

2.1. ILM - позволяет автоматически управлять жизненным циклом индексов Elasticsearch на основе политик.
Основные фазы ILM: Hot (горячая), Warm (теплая), Cold (холодная), Delete (удаление). Индекс создается в фазе Hot и активно используется для записи. В нашем случае hot-3 (3 дня), hot-7 (7 дней).

2.2. Index pattern — это шаблон, используемый в Kibana для работы с группой индексов, которые имеют схожие имена. Он позволяет Kibana выполнять запросы к множеству индексов одновременно. В нашем случае паттерн **nginx-logs-***

2.3. Data view - расширенная версия index pattern для интеграции различных источников данных. Если у вас есть несколько различных источников данных (логи NGINX, PostgreSQL и т. д.), можно создать data view, который объединяет их в одной панели для анализа.

3. Опишите логику работы Vector, grok patterns

3.1. Vector - это инструмент сбора, обработки и отправки логов и других потоков данных в различные хранилища. В нашем случае получаем данные из Kafka и отправляем в Elasticsearch. Он позволяет централизовать обработку данных и оптимизировать их поток в реальном времени. Основные этапы работы Vector: источники данных (Sources), трансформации данных (Transforms), синхронизация с хранилищем (Sinks). Получается в нашем случае kafka, grok, elasticsearch. Grok позволяют извлекать структурированные данные из текстовых логов. В проекте есть файл **vector.yaml**, где я писал эти пункты.